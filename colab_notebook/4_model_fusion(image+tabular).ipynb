{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5cB2HfMxV-4r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import root_mean_squared_error, r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCVgzLJ7WaVM",
        "outputId": "40f4dca8-fbf1-43c7-cdf7-6172e7cc3541"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Raw Data & Match with Available Images"
      ],
      "metadata": {
        "id": "1mZE7TepaHYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = Path.cwd().parent if \"notebooks\" in str(Path.cwd()) else Path.cwd()\n",
        "\n",
        "raw_df = pd.read_csv(\"/content/drive/MyDrive/satellite-property-valuation/data/raw/train_data.csv\")\n",
        "raw_df[\"id\"] = raw_df[\"id\"].astype(int)\n",
        "\n",
        "IMG_DIR = \"/content/drive/MyDrive/satellite-property-valuation/data/images\"\n"
      ],
      "metadata": {
        "id": "c8tKSIaAEdQm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "available_ids = sorted(\n",
        "    int(float(p.stem)) for p in Path(IMG_DIR).glob(\"*.png\")\n",
        ")\n",
        "\n",
        "fusion_df = (\n",
        "    raw_df[raw_df[\"id\"].isin(available_ids)]\n",
        "    .drop_duplicates(\"id\")\n",
        "    .sort_values(\"id\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "assert len(fusion_df) == len(available_ids)"
      ],
      "metadata": {
        "id": "B1esfCfHEed9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fusion_df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J58QxBWEku5",
        "outputId": "7e0cefbd-ce67-448a-cafc-d60fb1d90170"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5488, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resolve Image Paths"
      ],
      "metadata": {
        "id": "rH0HV0FvaoDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_paths = []\n",
        "\n",
        "# Convert IMG_DIR to a Path object to enable path joining with the / operator\n",
        "img_dir_path_obj = Path(IMG_DIR)\n",
        "\n",
        "for pid in fusion_df[\"id\"].values:\n",
        "    p1 = img_dir_path_obj / f\"{pid}.0.png\"\n",
        "    p2 = img_dir_path_obj / f\"{pid}.png\"\n",
        "    img_paths.append(p1 if p1.exists() else p2)\n",
        "\n",
        "len(img_paths), img_paths[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUoWzvMrEnmC",
        "outputId": "e48a4fcc-c771-42b8-e211-e7a9914dca77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5488,\n",
              " [PosixPath('/content/drive/MyDrive/satellite-property-valuation/data/images/1200019.0.png'),\n",
              "  PosixPath('/content/drive/MyDrive/satellite-property-valuation/data/images/1200021.0.png'),\n",
              "  PosixPath('/content/drive/MyDrive/satellite-property-valuation/data/images/3600057.0.png')])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Transform & Dataset"
      ],
      "metadata": {
        "id": "-VB98KeVavIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_tfms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=(0.485, 0.456, 0.406),\n",
        "        std=(0.229, 0.224, 0.225)\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "LMnALvW8EoOh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageOnlyDataset(Dataset):\n",
        "    def __init__(self, paths, transform):\n",
        "        self.paths = paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        return self.transform(img)\n"
      ],
      "metadata": {
        "id": "aMCwB-pOEsj-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Backbone for Image Embeddings"
      ],
      "metadata": {
        "id": "MWVApB_eazPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = models.resnet18(\n",
        "    weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
        ")\n",
        "cnn.fc = nn.Identity()\n",
        "\n",
        "for param in cnn.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "cnn = cnn.to(device)\n",
        "cnn.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFIjdxxuEtdC",
        "outputId": "f46c8a21-e979-462b-fd62-81dacba5331e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 60.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Identity()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Image Features"
      ],
      "metadata": {
        "id": "r2xNS5bta2zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_dataset = ImageOnlyDataset(img_paths, img_tfms)\n",
        "img_loader = DataLoader(\n",
        "    img_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "y_mnwtqvExYr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_features = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in img_loader:\n",
        "        batch = batch.to(device)\n",
        "        feats = cnn(batch)\n",
        "        img_features.append(feats.cpu().numpy())\n",
        "\n",
        "X_img = np.vstack(img_features)\n",
        "X_img.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAxkGKJJEyA0",
        "outputId": "c0095809-046d-4a78-e4a8-2af2d3aeed5c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5488, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\n",
        "    \"/content/drive/MyDrive/satellite-property-valuation/data/processed/image_embeddings_fusion.npy\",\n",
        "    X_img\n",
        ")\n"
      ],
      "metadata": {
        "id": "vFWDqUgrE2MS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Tabular Features"
      ],
      "metadata": {
        "id": "2faWpZIZa9RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = \"price\"\n",
        "drop_cols = [\"id\", \"date\", target_col]\n",
        "\n",
        "X_tab = fusion_df.drop(columns=drop_cols)\n",
        "y = np.log1p(fusion_df[target_col].values)\n"
      ],
      "metadata": {
        "id": "mBpNNbGVE55D"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_tab_scaled = scaler.fit_transform(X_tab)\n",
        "\n",
        "X_tab_scaled.shape, y.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNGitfASE9TX",
        "outputId": "fe366323-9f04-483c-9587-47a5e940c566"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5488, 18), (5488,))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early Fusion (Concatenation)"
      ],
      "metadata": {
        "id": "jPgnOFIWbB3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_fused = np.concatenate([X_tab_scaled, X_img], axis=1)\n",
        "X_fused.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UybqlAl0E_dG",
        "outputId": "be4feec1-8bdb-4cfe-b1a1-ad8d626eef1a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5488, 530)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train–Validation Split"
      ],
      "metadata": {
        "id": "isOohJUvbF4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "    X_fused,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "0Du8tCJTE__d"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch Datasets"
      ],
      "metadata": {
        "id": "bTEHKo1tbHWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr_t = torch.tensor(X_tr, dtype=torch.float32)\n",
        "y_tr_t = torch.tensor(y_tr, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_va_t = torch.tensor(X_va, dtype=torch.float32)\n",
        "y_va_t = torch.tensor(y_va, dtype=torch.float32).unsqueeze(1)\n"
      ],
      "metadata": {
        "id": "FQUfZXLJFFSx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(\n",
        "    TensorDataset(X_tr_t, y_tr_t),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dl = DataLoader(\n",
        "    TensorDataset(X_va_t, y_va_t),\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "ewM8JCeMFKIm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fusion Regressor Network"
      ],
      "metadata": {
        "id": "2wdHzNOzbN0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FusionRegressor(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "mhYs_HB6FK8b"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fusion_model = FusionRegressor(X_tr.shape[1]).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    fusion_model.parameters(),\n",
        "    lr=3e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "L5FVUD7SFNGx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "URDlREhsbSgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "\n",
        "for ep in range(epochs):\n",
        "    fusion_model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = fusion_model(xb)\n",
        "        loss = loss_fn(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    train_loss /= len(train_dl.dataset)\n",
        "\n",
        "    fusion_model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds = fusion_model(xb)\n",
        "            val_loss += loss_fn(preds, yb).item() * xb.size(0)\n",
        "\n",
        "    val_loss /= len(val_dl.dataset)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {ep+1}/{epochs} | \"\n",
        "        f\"Train MSE: {train_loss:.4f} | \"\n",
        "        f\"Val MSE: {val_loss:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH24jN6BFPBm",
        "outputId": "7f7697c4-ea11-4662-f179-fc5177b83add"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 | Train MSE: 42.3523 | Val MSE: 3.8176\n",
            "Epoch 2/15 | Train MSE: 3.0665 | Val MSE: 2.2683\n",
            "Epoch 3/15 | Train MSE: 1.7025 | Val MSE: 1.2625\n",
            "Epoch 4/15 | Train MSE: 1.0417 | Val MSE: 0.8589\n",
            "Epoch 5/15 | Train MSE: 0.7293 | Val MSE: 0.6439\n",
            "Epoch 6/15 | Train MSE: 0.5832 | Val MSE: 0.5503\n",
            "Epoch 7/15 | Train MSE: 0.5024 | Val MSE: 0.4998\n",
            "Epoch 8/15 | Train MSE: 0.4534 | Val MSE: 0.5106\n",
            "Epoch 9/15 | Train MSE: 0.4216 | Val MSE: 0.4406\n",
            "Epoch 10/15 | Train MSE: 0.3901 | Val MSE: 0.4263\n",
            "Epoch 11/15 | Train MSE: 0.3722 | Val MSE: 0.4164\n",
            "Epoch 12/15 | Train MSE: 0.3548 | Val MSE: 0.3953\n",
            "Epoch 13/15 | Train MSE: 0.3432 | Val MSE: 0.3849\n",
            "Epoch 14/15 | Train MSE: 0.3321 | Val MSE: 0.3750\n",
            "Epoch 15/15 | Train MSE: 0.3141 | Val MSE: 0.3662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Evaluation"
      ],
      "metadata": {
        "id": "f774ljThbUIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fusion_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds_log = fusion_model(X_va_t.to(device)).cpu().numpy().ravel()\n",
        "\n",
        "pred_price = np.expm1(preds_log)\n",
        "true_price = np.expm1(y_va)\n"
      ],
      "metadata": {
        "id": "Yqt0wB0tFQ6z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = root_mean_squared_error(true_price, pred_price)\n",
        "r2 = r2_score(true_price, pred_price)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²  : {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9UF5jv0FS8k",
        "outputId": "b8c0cdf5-d0cc-4299-8e5d-52fe48836fc3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 489662.99\n",
            "R²  : -0.6775\n"
          ]
        }
      ]
    }
  ]
}