{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CTGHnE94p17"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hcxQ6x24tHO",
        "outputId": "1066dbfa-5717-4a13-c9a2-b8e82079f13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "23nOmXvETfPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=(0.485, 0.456, 0.406),\n",
        "        std=(0.229, 0.224, 0.225)\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "M8iJwHv04vTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Dataset (Images Only)"
      ],
      "metadata": {
        "id": "jI92-AphTgus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PropertyImageDataset(Dataset):\n",
        "    def __init__(self, table, transform=None):\n",
        "        self.data = table.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_file = self.data.loc[index, \"image_path\"]\n",
        "        img = Image.open(img_file).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "pu_XExoS4yuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Image-Linked Metadata"
      ],
      "metadata": {
        "id": "IPalOMwoToha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = Path.cwd().parent if \"notebooks\" in str(Path.cwd()) else Path.cwd()\n",
        "\n",
        "img_meta = pd.read_csv(\"/content/drive/MyDrive/satellite-property-valuation/data/processed/train_with_images.csv\")\n",
        "\n",
        "img_meta[\"id\"] = img_meta[\"id\"].astype(float)\n",
        "\n",
        "IMG_ROOT = BASE_DIR / \"/content/drive/MyDrive/satellite-property-valuation/data/images\"\n",
        "\n",
        "img_meta[\"image_path\"] = img_meta[\"id\"].apply(\n",
        "    lambda v: IMG_ROOT / f\"{v}.png\"\n",
        ")\n",
        "\n",
        "img_meta[\"exists\"] = img_meta[\"image_path\"].apply(lambda p: p.exists())\n",
        "img_meta = img_meta[img_meta[\"exists\"]].reset_index(drop=True)\n",
        "\n",
        "img_meta.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ysGot041N6",
        "outputId": "69f9353c-6512-4bdc-d24f-774faf7c2039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5500, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_meta[[\"id\", \"price\", \"image_path\"]].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4K0s0G8r5f5k",
        "outputId": "5e37210e-a2c3-4488-a380-4de65ba1bffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id   price                                         image_path\n",
              "0  1.105001e+09  240000  /content/drive/MyDrive/satellite-property-valu...\n",
              "1  3.990002e+08  200000  /content/drive/MyDrive/satellite-property-valu...\n",
              "2  5.220593e+08  157500  /content/drive/MyDrive/satellite-property-valu...\n",
              "3  1.061400e+09  240000  /content/drive/MyDrive/satellite-property-valu...\n",
              "4  1.099600e+09  210000  /content/drive/MyDrive/satellite-property-valu..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65ffd39c-4bd0-4f8b-8dc2-446d4eac0227\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>price</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.105001e+09</td>\n",
              "      <td>240000</td>\n",
              "      <td>/content/drive/MyDrive/satellite-property-valu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.990002e+08</td>\n",
              "      <td>200000</td>\n",
              "      <td>/content/drive/MyDrive/satellite-property-valu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.220593e+08</td>\n",
              "      <td>157500</td>\n",
              "      <td>/content/drive/MyDrive/satellite-property-valu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.061400e+09</td>\n",
              "      <td>240000</td>\n",
              "      <td>/content/drive/MyDrive/satellite-property-valu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.099600e+09</td>\n",
              "      <td>210000</td>\n",
              "      <td>/content/drive/MyDrive/satellite-property-valu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65ffd39c-4bd0-4f8b-8dc2-446d4eac0227')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65ffd39c-4bd0-4f8b-8dc2-446d4eac0227 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65ffd39c-4bd0-4f8b-8dc2-446d4eac0227');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35adb0bb-c600-4e9e-8986-3ab6f7aa23bb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35adb0bb-c600-4e9e-8986-3ab6f7aa23bb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35adb0bb-c600-4e9e-8986-3ab6f7aa23bb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"img_meta[[\\\"id\\\", \\\"price\\\", \\\"image_path\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 347192034.55262226,\n        \"min\": 399000195.0,\n        \"max\": 1105000787.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          399000195.0,\n          1099600010.0,\n          522059327.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34113,\n        \"min\": 157500,\n        \"max\": 240000,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          200000,\n          210000,\n          240000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/drive/MyDrive/satellite-property-valuation/data/images/399000195.0.png\",\n          \"/content/drive/MyDrive/satellite-property-valuation/data/images/1099600010.0.png\",\n          \"/content/drive/MyDrive/satellite-property-valuation/data/images/522059327.0.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Backbone (Feature Extractor)"
      ],
      "metadata": {
        "id": "_WK0UIZhTu_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# remove classifier\n",
        "resnet_model.fc = nn.Identity()\n",
        "\n",
        "# freeze backbone\n",
        "for p in resnet_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "resnet_model = resnet_model.to(device)\n",
        "resnet_model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNcoCD605G8Q",
        "outputId": "d16dc01f-b082-4b3b-bc62-ffc517117eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Identity()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Image Embeddings"
      ],
      "metadata": {
        "id": "15JtCBRgTz1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_ds = PropertyImageDataset(\n",
        "    table=img_meta,\n",
        "    transform=img_transform\n",
        ")\n",
        "\n",
        "img_dl = DataLoader(\n",
        "    img_ds,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "aPuxBd-D5Kb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in img_dl:\n",
        "        batch = batch.to(device)\n",
        "        vecs = resnet_model(batch)\n",
        "        features.append(vecs.cpu().numpy())\n",
        "\n",
        "image_features = np.vstack(features)\n",
        "image_features.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg1r48br5M3E",
        "outputId": "b9afc218-b6ee-4cda-debd-188518b5ee1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5500, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Embeddings & Targets"
      ],
      "metadata": {
        "id": "zlZY7QevT7rG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\n",
        "     \"/content/drive/MyDrive/satellite-property-valuation/data/processed/image_embeddings.npy\",\n",
        "    image_features\n",
        ")\n",
        "\n",
        "img_meta[[\"id\", \"price\"]].to_csv(\n",
        "     \"/content/drive/MyDrive/satellite-property-valuation/data/processed/image_targets.csv\",\n",
        "    index=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "350OogLZDdMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Training Arrays"
      ],
      "metadata": {
        "id": "noStGZZFUBwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load(\"/content/drive/MyDrive/satellite-property-valuation/data/processed/image_embeddings.npy\")\n",
        "\n",
        "targets = pd.read_csv(\"/content/drive/MyDrive/satellite-property-valuation/data/processed/image_targets.csv\")\n",
        "y = np.log1p(targets[\"price\"].values)\n",
        "\n",
        "X.shape, y.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGVMXVmZDeT9",
        "outputId": "287b002a-ad0a-4586-fced-be640b7afe0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5500, 512), (5500,))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainâ€“Validation Split"
      ],
      "metadata": {
        "id": "vBrEZYm0UFTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "QWWTaXSuDhfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch Datasets"
      ],
      "metadata": {
        "id": "L1Jjfbh9UIkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr_t = torch.tensor(X_tr, dtype=torch.float32)\n",
        "y_tr_t = torch.tensor(y_tr, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_va_t = torch.tensor(X_va, dtype=torch.float32)\n",
        "y_va_t = torch.tensor(y_va, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_set = TensorDataset(X_tr_t, y_tr_t)\n",
        "val_set   = TensorDataset(X_va_t, y_va_t)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_set, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "ervd7-PDDkWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image-Only Regression Head"
      ],
      "metadata": {
        "id": "JZmxNd9YUJv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n"
      ],
      "metadata": {
        "id": "e4jVpIKuDp4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_model = ImageRegressor().to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(img_model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "OK2JRbbJDts0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "AcwP7WwyUR13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for ep in range(epochs):\n",
        "    img_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = img_model(xb)\n",
        "        loss = loss_fn(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    total_loss /= len(train_loader.dataset)\n",
        "\n",
        "    img_model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds = img_model(xb)\n",
        "            val_loss += loss_fn(preds, yb).item() * xb.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {ep+1}/{epochs} | \"\n",
        "        f\"Train MSE: {total_loss:.4f} | \"\n",
        "        f\"Val MSE: {val_loss:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0FCT9aLDxI2",
        "outputId": "360b97e6-402e-475c-dcdb-934a208a9dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train MSE: 14.2590 | Val MSE: 2.5225\n",
            "Epoch 2/10 | Train MSE: 1.9337 | Val MSE: 1.4836\n",
            "Epoch 3/10 | Train MSE: 1.3347 | Val MSE: 1.1220\n",
            "Epoch 4/10 | Train MSE: 1.0458 | Val MSE: 0.9036\n",
            "Epoch 5/10 | Train MSE: 0.8757 | Val MSE: 0.8233\n",
            "Epoch 6/10 | Train MSE: 0.7750 | Val MSE: 0.7065\n",
            "Epoch 7/10 | Train MSE: 0.6867 | Val MSE: 0.6398\n",
            "Epoch 8/10 | Train MSE: 0.6289 | Val MSE: 0.6002\n",
            "Epoch 9/10 | Train MSE: 0.5911 | Val MSE: 0.5699\n",
            "Epoch 10/10 | Train MSE: 0.5589 | Val MSE: 0.5667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Evaluation"
      ],
      "metadata": {
        "id": "iMcakm2lUVdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_model.eval()\n",
        "\n",
        "pred_log, true_log = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(device)\n",
        "        out = img_model(xb)\n",
        "\n",
        "        pred_log.append(out.cpu().numpy())\n",
        "        true_log.append(yb.cpu().numpy())\n",
        "\n",
        "pred_log = np.vstack(pred_log).ravel()\n",
        "true_log = np.vstack(true_log).ravel()\n"
      ],
      "metadata": {
        "id": "YgrCgSmrDyAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import root_mean_squared_error, r2_score\n",
        "\n",
        "pred_price = np.expm1(pred_log)\n",
        "true_price = np.expm1(true_log)\n",
        "\n",
        "rmse = root_mean_squared_error(true_price, pred_price)\n",
        "r2 = r2_score(true_price, pred_price)\n",
        "\n",
        "rmse, r2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNh81X2AD0oW",
        "outputId": "b24b2dc5-5d4e-477c-d82d-7ae23f22b092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(549792.75, -1.2756156921386719)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image-only model captures visual neighborhood context\n",
        "\n",
        "Performance is weaker than tabular baseline\n",
        "\n",
        "Confirms that images alone are insufficient\n",
        "\n",
        "Justifies multimodal fusion (tabular + image)"
      ],
      "metadata": {
        "id": "3-TVsMh4UbF2"
      }
    }
  ]
}